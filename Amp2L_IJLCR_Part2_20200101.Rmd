---
title: "A corpus-based analysis of adjective amplification among native speakers and learners of English"
author: "Anonymous"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  bookdown::html_document2: default
bibliography: bibliography.bib
link-citations: yes
---

This document shows an analysis that was performed with the aim of finding differences in adjective amplification between learners of English and native speakers based on the ICLE. 

In a first step, the session is prepared by clearing the workspace, setting options, activating packages and functions, as well as loading relevant functions.

```{r l2amp_01, echo=T, eval = T, message=FALSE, warning=FALSE}
# clean current workspace
rm(list=ls(all=T))                                      
# load packages
library(stringr) 
# set options
options(stringsAsFactors = F)                           
options(scipen = 999) 
# define image directory
imageDirectory<-"images" 
# specify path to corpus
corpus.locness <- "D:\\Uni\\Korpora\\Original\\LOCNESS" 
```

Next, the data is loaded and displayed.

```{r l2amp_02, echo=T, eval = T, message=FALSE, warning=FALSE}
# define files to load
corpus.files = list.files(path = corpus.locness, pattern = ".txt", all.files = T,
                           full.names = T, recursive = T, ignore.case = T, include.dirs = T)
Content <- sapply(corpus.files, function(x) {
  x <- scan(x, what = "char", sep = "", quote = "\"", quiet = T, skipNul = T)
  x <- gsub(" {2,}", " ", x)
  x <- str_trim(x, side = "both")
  x <- paste(x, sep = " ", collapse = " ")
})
Language <- rep("English", length(Content))
File <- gsub(".*/", "", corpus.files)
File <- gsub(".txt", "", File)
CleanContent <- gsub(" {2,}", " ", Content)
# combine vectors to data frame
locness <- as.data.frame(cbind(Language, File, Content, CleanContent))
# check data
head(locness[,1:2]); nrow(locness)

# remove elements that are shorter than 1000 characters
locness <- locness[nchar(locness$CleanContent) >= 1000,]
```

Next, the data is processed and saved.

```{r l2amp_03, echo=T, eval = T, message=FALSE, warning=FALSE}
# save data to disc
write.table(locness, "datatables/locness_raw01.txt", sep = "\t", row.names = F, col.names = T, quote = T)
# WARNING: DO NOT ACTIVATE!
#locness <- read.table("datatables/locness_raw01.txt", sep = "\t", header = T)#, skipNul = T, quote = "\"", fill = T)
```

In a next step, the data are part-of-speech tagged.

```{r l2amp_04, echo=T, eval = T, message=FALSE, warning=FALSE}
# split data into smaller chunks
pos01 <- locness$CleanContent[1]
pos02 <- locness$CleanContent[2]
pos03 <- locness$CleanContent[3]
pos04 <- locness$CleanContent[4]
pos05 <- locness$CleanContent[5]
pos06 <- locness$CleanContent[6]
pos07 <- locness$CleanContent[7]
pos08 <- locness$CleanContent[8]
pos09 <- locness$CleanContent[9]
pos10 <- locness$CleanContent[10]
pos11 <- locness$CleanContent[11]
pos12 <- locness$CleanContent[12]
pos13 <- substring(locness$CleanContent[13], 1, 200000)
pos14 <- substring(locness$CleanContent[13], 200001, 400000)
pos15 <- substring(locness$CleanContent[13], 400001, 600000)
pos16 <- substring(locness$CleanContent[13], 600001, 800000)
pos17 <- substring(locness$CleanContent[13], 800001, nchar(locness$CleanContent[13]))
pos18 <- locness$CleanContent[14]
# reload libraries
source("D:\\R/POStagObject.R") # for pos-tagging objects in R
library(NLP)
library(openNLP)
library(openNLPmodels.en)
# pos tagging data
locnesspos01 <- POStag(object = pos01)
locnesspos01 <- as.vector(unlist(locnesspos01))
writeLines(locnesspos01, con = "datatables/locnesspos01.txt", sep = "\n", useBytes = FALSE)
# chunk 2
locnesspos02 <- POStag(object = pos02)
locnesspos02 <- as.vector(unlist(locnesspos02))
writeLines(locnesspos02, con = "datatables/locnesspos02.txt", sep = "\n", useBytes = FALSE)
# chunk 03
locnesspos03 <- POStag(object = pos03)
locnesspos03 <- as.vector(unlist(locnesspos03))
writeLines(locnesspos03, con = "datatables/locnesspos03.txt", sep = "\n", useBytes = FALSE)
# chunk 04
locnesspos04 <- POStag(object = pos04)
locnesspos04 <- as.vector(unlist(locnesspos04))
writeLines(locnesspos04, con = "datatables/locnesspos04.txt", sep = "\n", useBytes = FALSE)
# chunk 05
locnesspos05 <- POStag(object = pos05)
locnesspos05 <- as.vector(unlist(locnesspos05))
writeLines(locnesspos05, con = "datatables/locnesspos05.txt", sep = "\n", useBytes = FALSE)
# chunk 06
locnesspos06 <- POStag(object = pos06)
locnesspos06 <- as.vector(unlist(locnesspos06))
writeLines(locnesspos06, con = "datatables/locnesspos06.txt", sep = "\n", useBytes = FALSE)
# chunk 07
locnesspos07 <- POStag(object = pos07)
locnesspos07 <- as.vector(unlist(locnesspos07))
writeLines(locnesspos07, con = "datatables/locnesspos07.txt", sep = "\n", useBytes = FALSE)
# chunk 08
locnesspos08 <- POStag(object = pos08)
locnesspos08 <- as.vector(unlist(locnesspos08))
writeLines(locnesspos08, con = "datatables/locnesspos08.txt", sep = "\n", useBytes = FALSE)
# chunk 09
locnesspos09 <- POStag(object = pos09)
locnesspos09 <- as.vector(unlist(locnesspos09))
writeLines(locnesspos09, con = "datatables/locnesspos09.txt", sep = "\n", useBytes = FALSE)
# chunk 010
locnesspos10 <- POStag(object = pos10)
locnesspos10 <- as.vector(unlist(locnesspos10))
writeLines(locnesspos10, con = "datatables/locnesspos10.txt", sep = "\n", useBytes = FALSE)
# chunk 011
locnesspos11 <- POStag(object = pos11)
locnesspos11 <- as.vector(unlist(locnesspos11))
writeLines(locnesspos11, con = "datatables/locnesspos11.txt", sep = "\n", useBytes = FALSE)
# chunk 12
locnesspos12 <- POStag(object = pos12)
locnesspos12 <- as.vector(unlist(locnesspos12))
writeLines(locnesspos12, con = "datatables/locnesspos12.txt", sep = "\n", useBytes = FALSE)
# chunk 13
locnesspos13 <- POStag(object = pos13)
locnesspos13 <- as.vector(unlist(locnesspos13))
writeLines(locnesspos13, con = "datatables/locnesspos13.txt", sep = "\n", useBytes = FALSE)
# chunk 14
locnesspos14 <- POStag(object = pos14)
locnesspos14 <- as.vector(unlist(locnesspos14))
writeLines(locnesspos14, con = "datatables/locnesspos14.txt", sep = "\n", useBytes = FALSE)
# chunk 15
locnesspos15 <- POStag(object = pos15)
locnesspos15 <- as.vector(unlist(locnesspos15))
writeLines(locnesspos15, con = "datatables/locnesspos15.txt", sep = "\n", useBytes = FALSE)
# chunk 16
locnesspos16 <- POStag(object = pos16)
locnesspos16 <- as.vector(unlist(locnesspos16))
writeLines(locnesspos16, con = "datatables/locnesspos16.txt", sep = "\n", useBytes = FALSE)
# chunk 17
locnesspos17 <- POStag(object = pos17)
locnesspos17 <- as.vector(unlist(locnesspos17))
writeLines(locnesspos17, con = "datatables/locnesspos17.txt", sep = "\n", useBytes = FALSE)
# chunk 18
locnesspos18 <- POStag(object = pos18)
locnesspos18 <- as.vector(unlist(locnesspos18))
writeLines(locnesspos18, con = "datatables/locnesspos18.txt", sep = "\n", useBytes = FALSE)
# list pos tagged elements
postag.files = c("datatables/locnesspos01.txt", "datatables/locnesspos02.txt", "datatables/locnesspos03.txt",  
                 "datatables/locnesspos04.txt","datatables/locnesspos05.txt", "datatables/locnesspos06.txt",  
                 "datatables/locnesspos07.txt", "datatables/locnesspos08.txt", "datatables/locnesspos09.txt", 
                 "datatables/locnesspos10.txt", "datatables/locnesspos11.txt", "datatables/locnesspos12.txt",
                 "datatables/locnesspos13.txt", "datatables/locnesspos14.txt", "datatables/locnesspos15.txt", 
                 "datatables/locnesspos16.txt", "datatables/locnesspos17.txt", "datatables/locnesspos18.txt")
# load pos tagged elements
locnesspos <- sapply(postag.files, function(x) {
  x <- scan(x, what = "char", sep = "\n", quote = "", quiet = T, skipNul = T)
  x <- gsub(" {2,}", " ", x)
  x <- str_trim(x, side = "both")
  x <- str_replace_all(x, fixed("\n"), " ")
})
locnesspos13 <- paste(locnesspos[13:17], sep = " ", collapse = " ")
locnesspos <- c(locnesspos[1:12], locnesspos13, locnesspos[18])                           
# unlist pos tagged elements
locness$locnesspos <- unlist(locnesspos)
```

In a next step, we create the concordances which target adjectives (JJ) in the ICLE data.

```{r l2amp_05, echo=T, eval = T, message=FALSE, warning=FALSE}
# extract number of adjs per line
pstggd <- locness$locnesspos
lpstggd <- strsplit(pstggd, " ")
nlpstggd <- as.vector(unlist(sapply(lpstggd, function(x){
  x <- x[grep("[A-Z]{0,1}[a-z]{1,}\\/JJ[A-Z]{0,1}", x)]
  x <- length(x) } )))
rp <- nlpstggd
rp <- ifelse(rp == 0, 1, rp)
# load function for concordancing
library(plyr)
source("D:\\R/ConcR_2.3_loadedfiles.R")
# set parameters for concordancing
pattern <- "[A-Z]{0,1}[a-z]{1,}\\/JJ[A-Z]{0,1}"
context <- 50
# extract all adjectives (concordance)
concjjlocness <- ConcR(locness$locnesspos, pattern, context, all.pre = FALSE)
# repeat rows in data frame as often as there are adjectives in it (if 0 adj, repeat once)
corpuslocnessadjdf <- locness[rep(seq(nrow(locness)), rp),]
# combine data sets
corpuslocnessadj <- data.frame(1:nrow(corpuslocnessadjdf), corpuslocnessadjdf, concjjlocness)
# remove rows without Tokens
amplocness <- corpuslocnessadj[is.na(corpuslocnessadj$Token) == F,]
# add clean column names
colnames(amplocness) <- c("ID", "Language", "File", "Content", "ContentClean", 
                          "PosTaggedContent", "OriginalString", "PreContext", 
                          "Adjective", "PostContext")
# clean adjectives
amplocness$Adjective <- gsub(".*/JJR", "remove", amplocness$Adjective)
amplocness$Adjective <- gsub(".*/JJS", "remove", amplocness$Adjective)
amlocness <- amplocness[!amplocness$Adjective == "remove",]
amplocness$Adjective <- str_replace_all(amplocness$Adjective, fixed("/JJ"), "")
# add Vraiant column
amplocness$Variant <- gsub(".* ", "", str_trim(amplocness$PreContext, side = "both")) 
# inspect data
nrow(amplocness); head(amplocness)
```

Now, we check which adjectives were amplified.

```{r l2amp_06, echo=T, eval = T, message=FALSE, warning=FALSE}
# define amplifiers
amplifiers <- c("absolutely", "actually", "aggressively", 
                "amazingly", "appallingly", "awful", "awfully", 
                "badly", "bloody", "certainly", "clearly",
                "complete", "dead", "completely", "considerably", 
                "crazy", "decidedly", "definitely",  "distinctly", 
                "dreadfully", "enormously", "entirely", "especially", 
                "exactly", "exceedingly", "exceptionally", 
                "excruciatingly", "extraordinarily", "extremely",
                "fiercely", "firmly", "frightfully", "fucking", 
                "fully", "genuinely", "greatly",
                "grossly", "heavily", "highly", "hopelessly", 
                "horrendously", "hugely",
                "immediately", "immensely", "incredibly", 
                "infinitely", "intensely", "irrevocably",
                "mad", "mega", "mighty", #"most", "much", 
                "obviously", "openly", "overwhelmingly", "particularly", 
                "perfectly", "plenty", "positively", "precisely", 
                "pretty", "profoundly", "purely", 
                #"quite", 
                "real", "really", "remarkably", "seriously", 
                "shocking",   "significant", "significantly", "so", 
                "specially", "specifically", "strikingly",
                "strongly", "substantially", "super", "surely", 
                "terribly", "terrifically", 
                #"too",
                "total", "totally", "traditionally", #"true", 
                "truly", "ultra", "utterly", "very",
                "viciously", 
                #"well", 
                "wholly", "wicked", "wildly")
```

In a next step, we define rows that need to be removed.

```{r l2amp_07, echo=T, eval = T, message=FALSE, warning=FALSE}
# clean ice locness data
amplocness$Function <- str_trim(amplocness$PostContext, side = "both")
amplocness$Function <- tolower(amplocness$Function)
amplocness$Function <- gsub(" {2,}", " ", amplocness$Function)
amplocness$Function <- sub(" ", "", amplocness$Function)
amplocness$Function <- gsub(" .*", "", amplocness$Function)
amplocness$Function <- gsub(".*/nn.*", "Attributive", amplocness$Function)
amplocness$Function <- ifelse(amplocness$Function == "Attributive", amplocness$Function, "Predicative")
# shorten post Context
amplocness$PostContext <- substr(amplocness$PostContext, 1, ifelse((nchar(amplocness$PostContext)+25) <25, maamplocness(nchar(amplocness$PostContext)), 25))
# pre Context
amplocness$PreContext <- str_trim(amplocness$PreContext, side = "both")
amplocness$PreContextLong <- amplocness$PreContext
amplocness$PreContextLong <- substr(amplocness$PreContextLong, ifelse(nchar(amplocness$PreContextLong)-25 <=0, 1, 
                                                                      nchar(amplocness$PreContextLong)-25), nchar(amplocness$PreContextLong))
amplocness$PreContext <- gsub(".* ", "", amplocness$PreContext)
# amplifier variant
amplocness$PreContext <- gsub("\\/.*", "", amplocness$PreContext)
amplocness$Variant <- ifelse(amplocness$PreContext %in% amplifiers, amplocness$PreContext, "0")
# amplified y/n
amplocness$Amplified <- ifelse(amplocness$Variant == "0", 0, 1) 
# adjective
amplocness$Adjective <- tolower(amplocness$Adjective)
# inspect data
nrow(amplocness); head(amplocness); table(amplocness$Variant)
```

Now, we remove the rows that were identified as problematic.

```{r l2amp_08, echo=T, eval = T, message=FALSE, warning=FALSE}
# define forms that require removal
sups <- c(".*most.*", ".*more.*") 
negs <- c(".*not.*", ".*never.*", ".*n't.*")
downtoners <- c(".*sort/.*", ".*kind/.*", ".* bit/.*", ".*somewhat.*", ".*fairly.*", 
                ".*rather.*", ".*reasonably.*", ".*slightly.*", ".*comparatively.*", ".*semi.*", 
                ".*relatively.*", ".*little.*", ".*somehow.*", ".*almost.*", ".*partly.*", 
                ".*hardly.*", ".* less.*", ".*barely.*", ".* just/.*")
specialforms <- c(".* too.*", ".*quite.*")
PostContextdowntoners <- c(".*enough.*")
nonpropadj <- c("only", "much", "many", "cheaper", "cheaperr", "bests", "larger", "such", "other")
# check length of dataset
str(amplocness); head(amplocness); nrow(amplocness)#; table(amplocness$pint); head(amplocness$PreContextLong); head(amplocness$PreContextLong)

# code priming
prim1 <- c(rep(0, 1), amplocness$Variant[1:length(amplocness$Variant)-1])
prim2 <- c(rep(0, 2), amplocness$Variant[1:(length(amplocness$Variant)-2)])
prim3 <- c(rep(0, 3), amplocness$Variant[1:(length(amplocness$Variant)-3)])
primtb <- cbind(amplocness$Variant, prim1, prim2, prim3)

amplocness$Priming <- as.vector(unlist(apply(primtb, 1, function(x){
  x <- ifelse(x[1]== "0" , "noprime",
              ifelse(x[1] == x[2] | x[1] == x[3] | x[1] == x[4], "prime", "noprime"))
})))
# remove items that were not intensified by a minimum of 2 intensifier variants
nrow(amplocness)

# find items to be removed
supsidx <- unique(grep(paste(sups,collapse="|"), amplocness$PreContextLong, value=F))
negsidx <- unique(grep(paste(negs,collapse="|"), amplocness$PreContextLong, value=F))
downtonersidx <- unique(grep(paste(downtoners,collapse="|"), amplocness$PreContextLong, value=F))
specialformsidx <- unique(grep(paste(specialforms,collapse="|"), amplocness$PreContextLong, value=F))
PostContextdowntonersidx <- unique(grep(paste(PostContextdowntoners,collapse="|"), amplocness$PostContext, value=F))
nonpropadjidx <- unique(grep(paste(nonpropadj,collapse="|"), amplocness$Adjective, value=F))
# combine indices
idxs <- unique(c(supsidx, negsidx, downtonersidx, specialformsidx, PostContextdowntonersidx, nonpropadjidx))
# remove forms that require removal
amplocness <- amplocness[-idxs,]
# remove empty values
amplocness <- amplocness[!amplocness$Variant == "", ]
# remove superfluous columns
colnames(amplocness)
amplocness$Content <- NULL
amplocness$ContentClean <- NULL
amplocness$PosTaggedContent <- NULL
amplocness$OriginalString <- NULL
```

Now, we save the new data set to the disc.

```{r l2amp_09, echo=T, eval = T, message=FALSE, warning=FALSE}
# save raw data to disc
write.table(amplocness, "datatables/amplocness_woneg02.txt", sep = "\t", row.names = F)
```

In a next step, we remove adjectives that were not amplified by at least two different amplifier types.
 
```{r l2amp_10, echo=T, eval = T, message=FALSE, warning=FALSE}
pintadjtb <- table(amplocness$Adjective, amplocness$Variant)
#pintadjtb <- pintadjtb[2:nrow(pintadjtb),]
pintadjtb <- pintadjtb[,2:ncol(pintadjtb)]
pintadjtb2 <- apply(pintadjtb, 1, function(x){
  x <- ifelse(x > 1, 1, x)})
pintadjtb3 <- colSums(pintadjtb2)
pintadjschildes <- names(pintadjtb3)[which(pintadjtb3 >= 1)]
amplocness <- amplocness[amplocness$Adjective %in% pintadjschildes, ]
nrow(amplocness)
```

Next, we inspect the remaining adjectives.

```{r l2amp_11, echo=T, eval = T, message=FALSE, warning=FALSE}
# inspect adjectives
adjtb <- names(table(amplocness$Adjective))
adjtb

write.table(adjtb, "datatables/adjtb_ns.txt", quote = F, sep = "\t")
# create vector with false adjectives
rmvadj <- c("uhr")
amplocness$remove <- ifelse(amplocness$Adjective %in% rmvadj, "remove", amplocness$Adjective)
amplocness <- amplocness[amplocness$remove != "remove",]
# remove superfluous columns
amplocness$remove <- NULL
colnames(amplocness)

# inspecta data
nrow(amplocness); length(table(amplocness$Adjective)); head(amplocness)
```

Now, we correct spelling mistakes and re-inspect the data.

```{r l2amp_12, echo=T, eval = T, message=FALSE, warning=FALSE}
# save raw data to disc
write.table(amplocness, "datatables/amplocness_semlocnessan03.txt", sep = "\t", row.names = F)
# tabluate amplifiers
table(amplocness$Variant)[order(table(amplocness$Variant), decreasing = T)]
```

We now inspect the amplifiers.

```{r l2amp_13, echo=T, eval = T, message=FALSE, warning=FALSE}
# create columns with intensifier freqs
amplocness$very <- ifelse(amplocness$Variant == "very", 1, 0) 
amplocness$so <- ifelse(amplocness$Variant == "so", 1, 0) 
amplocness$really <- ifelse(amplocness$Variant == "really", 1, 0)
amplocness$completely <- ifelse(amplocness$Variant == "completely", 1, 0) 
amplocness$extremely <- ifelse(amplocness$Variant == "extremely", 1, 0)
amplocness$other <- ifelse(amplocness$Variant == "extremely" |
                             amplocness$Variant == "really" | 
                             amplocness$Variant == "so" |
                             amplocness$Variant == "completely" |
                             amplocness$Variant == "very", 0, 1)
# inspect results
head(amplocness)
```

In a next step, we code the frequency of adjectives by L1.

```{r l2amp_14, echo=T, eval = T, message=FALSE, warning=FALSE}
# code freq of adj type by language
frqadjtb <- table(amplocness$Language, amplocness$Adjective)
relfreqadjtb <- round(prop.table(frqadjtb, margin = 1)*100, 5)
relfreqadjdf <- as.data.frame(relfreqadjtb)
colnames(relfreqadjdf)[1:2] <- c("Language", "Adjective")
# add freq by date to data
amplocness <- merge(amplocness, relfreqadjdf, by=c("Language", "Adjective"))
# reorder data
amplocness <- amplocness[order(amplocness$ID),]
# inspect data
head(amplocness)
```

In a next step, we code the gradability of adjectives based on the COCA.

```{r l2amp_15, echo=T, eval = T, message=FALSE, warning=FALSE}
# load Gradability data (derived from COCA)
gradability <- read.delim("datatables/Gradability.txt", sep = "\t", header = T, quote = "", skipNul = T)
amplocness$Gradability <- ifelse(amplocness$Adjective %in% gradability$Adjective, gradability$Beta, 1)
# inspect data
nrow(amplocness); head(amplocness)
```

Now, we add the semantci classification of adjectives.

```{r l2amp_16, echo=T, eval = T, message=FALSE, warning=FALSE}
# add semantic types (tagliamonte 2008, based on dixon 1977)
# dimension = semdim (e.g. big, large, little, small, long, short, wide, narrow, thick)
# difficulty = semdif (e.g. difficult, simple)
# physical property = (e.g. hard, soft, heavy, light, rough, smooth, hot, sweet)
# color = semcol (e.g. black, white, red)
# human propensity: semhup (e.g. jealous, happy, kind, clever, generous, gay, rude)
# age = semage (e.g. new, young, old) 
# value (e.g. good, bad, proper, perfect, excellent, delicious, poor), 
# speed Speed (fast, quick, slow)
# position (e.g. right, left, near, far)
# other
# load data
code1 <- read.delim("datatables/semcodecg1.txt", sep = "\t", 
                    header = T, skipNul = T)
code2 <- read.delim("datatables/semcodedjm1.txt", sep = "\t", 
                    header = T, skipNul = T)
code3 <- read.delim("datatables/semcodedl1.txt", sep = "\t", 
                    header = T, skipNul = T)
code4 <- read.delim("datatables/semcodedm1.txt", sep = "\t", 
                    header = T, skipNul = T)
code5 <- read.delim("datatables/semcodedma1.txt", sep = "\t", 
                    header = T, skipNul = T)
code6 <- read.delim("datatables/semcodedv1.txt", sep = "\t", 
                    header = T, skipNul = T)
code7 <- read.delim("datatables/semcodedjw1.txt", sep = "\t", 
                    header = T, skipNul = T)
# order data sets
code1 <- code1[order(code1$Id),]
code2 <- code2[order(code2$Id),]
code3 <- code3[order(code3$Id),]
code4 <- code4[order(code4$Id),]
code5 <- code5[order(code5$Id),]
code6 <- code6[order(code6$Id),]
code7 <- code6[order(code7$Id),]
# repair adjectives in code1
code3$Adjective <- code1$Adjective
# combine tables
semcode <- rbind(code1, code2, code3, code4, code5, code6, code7)
# convert coding into numeric values
semcode[,3:12] <- t(apply(semcode[,3:12], 1, function(x) {
#  x <- ifelse(x == "" | is.na(x) == T, 0, 1)}))
  x <- ifelse(x == "" | x == "?"| is.na(x) == T, 0, 1)}))
# convert into data frame
semcode <- as.data.frame(semcode)
# add column names
colnames(semcode)[3:12] <- c("Dimension", "Difficulty", 
                             "PhysicalProperty", "Color",
                             "HumanPropensity", "Age", "Value", 
                             "Speed", "Position", "Other")
# load library
library(dplyr)
AdjectiveSemantics <- semcode %>%
  dplyr::group_by(Adjective) %>%
  na.omit() %>%
  dplyr::summarize(Dimension = sum(Dimension), Difficulty = sum(Difficulty),
                PhysicalProperty = sum(PhysicalProperty), Color = sum(Color),
                HumanPropensity = sum(HumanPropensity), Age = sum(Age),
                Value = sum(Value), Speed = sum(Speed),
                Position = sum(Position), Other = sum(Other)) %>%
  dplyr::mutate(OverallScore = rowSums(.[,2:11])) %>%
  dplyr::mutate(Maximum = do.call(pmax, (.[,2:11]))) %>%
  dplyr::mutate(Certainty = Maximum/OverallScore*100)
AdjectiveSemantics <- AdjectiveSemantics %>%
  dplyr::mutate(Category = colnames(AdjectiveSemantics[2:11])[apply(AdjectiveSemantics[2:11],1,which.max)])
# inspect interrater reliability
summary(AdjectiveSemantics$Certainty)

# create vectors
Age <- as.vector(unlist(AdjectiveSemantics %>%
                   dplyr::filter(Category == "Age") %>% select(Adjective)))
Color <- as.vector(unlist(AdjectiveSemantics %>%
                          dplyr::filter(Category == "Color") %>% select(Adjective)))
Difficulty <- as.vector(unlist(AdjectiveSemantics %>%
                          dplyr::filter(Category == "Difficulty") %>% select(Adjective)))
Dimension <- as.vector(unlist(AdjectiveSemantics %>%
                          dplyr::filter(Category == "Dimension") %>% select(Adjective)))
HumanPropensity <- as.vector(unlist(AdjectiveSemantics %>%
                          dplyr::filter(Category == "HumanPropensity") %>% select(Adjective)))
PhysicalProperty <- as.vector(unlist(AdjectiveSemantics %>%
                          dplyr::filter(Category == "PhysicalProperty") %>% select(Adjective)))
Position <- as.vector(unlist(AdjectiveSemantics %>%
                                       dplyr::filter(Category == "Position") %>% select(Adjective)))
Speed <- as.vector(unlist(AdjectiveSemantics %>%
                                       dplyr::filter(Category == "Speed") %>% select(Adjective)))
Value <- as.vector(unlist(AdjectiveSemantics %>%
                            dplyr::filter(Category == "Value") %>% select(Adjective)))
# add semantic category to data
amplocness$SemanticCategory <- ifelse(amplocness$Adjective %in% Age, "Age",
                                    ifelse(amplocness$Adjective %in% Color, "Color",
                                    ifelse(amplocness$Adjective %in% Difficulty, "Difficulty",
                                    ifelse(amplocness$Adjective %in% Dimension, "Dimension",
                                    ifelse(amplocness$Adjective %in% HumanPropensity, "HumanPropensity",
                                    ifelse(amplocness$Adjective %in% PhysicalProperty, "PhysicalProperty",
                                    ifelse(amplocness$Adjective %in% Position, "Position",
                                    ifelse(amplocness$Adjective %in% Speed, "Speed",
                                    ifelse(amplocness$Adjective %in% Value, "Value", "Other")))))))))
# table sem class of tokens
table(amplocness$SemanticCategory)

# inspect data
head(amplocness)
```

Now, we perform a sentiment analysis and annotate the emotionality of adjectives.

```{r l2amp_17, echo=T, eval = T, message=FALSE, warning=FALSE}
# load library
library(syuzhet)
# code emotion
class_emo <- get_nrc_sentiment(amplocness$Adjective)
# process sentiment
amplocness$Emotionality <- as.vector(unlist(apply(class_emo, 1, function(x){
  x <- ifelse(x[9] == 1, "NegativeEmotional",
              ifelse(x[10] == 1, "PositiveEmotional", "NonEmotional")) } )))
# revert order of factor Emotionality
amplocness$Emotionality <- factor(amplocness$Emotionality, levels = c("NonEmotional", "NegativeEmotional", "PositiveEmotional"))
# save raw data to disc
write.table(amplocness, "datatables/amplocness_clean04.txt", sep = "\t", row.names = F)
# inspect data
head(amplocness); str(amplocness); nrow(amplocness)
```

We have reached the end of part 2 of the analysis.
